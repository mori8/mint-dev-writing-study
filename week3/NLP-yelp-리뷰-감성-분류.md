> ì´ ê¸€ì€ í•œë¹›ë¯¸ë””ì–´ì˜ ['íŒŒì´í† ì¹˜ë¡œ ë°°ìš°ëŠ” ìì—°ì–´ì²˜ë¦¬'](http://www.yes24.com/Product/Goods/101874047) ê¸€ì„ ì½ê³  ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.

í¼ì…‰íŠ¸ë¡ ê³¼ ì§€ë„ í•™ìŠµ í›ˆë ¨ ë°©ë²•ì„ ì‚¬ìš©í•´ [ì˜í”„(Yelp)](https://ko.wikipedia.org/wiki/%EC%98%90%ED%94%84) ì˜ ë ˆìŠ¤í† ë‘ ë¦¬ë·°ê°€ ê¸ì •ì ì¸ì§€ ë¶€ì •ì ì¸ì§€ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ í•´ë³´ì. ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” ì „ì²´ ì½”ë“œëŠ” [ì—¬ê¸°](https://github.com/rickiepark/nlp-with-pytorch/blob/main/chapter_3/3_5_yelp_dataset_preprocessing_LITE.ipynb)ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

### Dataset: ì˜í”„ ë¦¬ë·° ë°ì´í„°ì…‹

ì´ ì‹¤ìŠµì—ì„œëŠ” 2015ë…„ì— ì˜í”„ê°€ ì£¼ìµœí•œ ë ˆìŠ¤í† ë‘ ë“±ê¸‰ ì˜ˆì¸¡ ëŒ€íšŒì—ì„œ ì‚¬ìš©ë˜ì—ˆë˜ ë ˆìŠ¤í† ë‘ ë¦¬ë·° ë°ì´í„°ë¥¼ ê°„ì†Œí™”í•œ ë’¤ í›ˆë ¨ ìƒ˜í”Œê³¼ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œë¡œ ë¶„ë¥˜í•´ ë‘” ë°ì´í„°ì…‹ ì¤‘ 10%ë¥¼ ì‚¬ìš©í•œë‹¤.

ì „ì²´ ë°ì´í„°ì…‹ ì¤‘ ì¼ë¶€ë§Œ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” í¬ê²Œ 2ê°€ì§€ê°€ ìˆë‹¤.

1.  ì‘ì€ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ë©´ í›ˆë ¨-í…ŒìŠ¤íŠ¸ ë°˜ë³µì´ ë¹ ë¥´ê²Œ ì´ë£¨ì–´ì ¸ **ì‹¤í—˜ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆë‹¤.**
2.  ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ë•Œë³´ë‹¤ ëª¨ë¸ì˜ ì •í™•ë„ê°€ ë‚®ë‹¤. ë‚®ì€ ì •í™•ë„ëŠ” ì¼ë°˜ì ìœ¼ë¡œ í¬ê²Œ ë¬¸ì œê°€ ë˜ì§€ ì•Šìœ¼ë©°, **ì‘ì€ ë°ì´í„°ì…‹ì—ì„œ ì–»ì€ ì§€ì‹ìœ¼ë¡œ ì „í…Œ ë°ì´í„°ì…‹ì—ì„œ ëª¨ë¸ì„ ë‹¤ì‹œ í›ˆë ¨í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—**, í›ˆë ¨ ë°ì´í„° ì–‘ì´ ì•„ì£¼ ë§ì„ ë•Œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆëŠ” ìœ ìš©í•œ ë°©ë²•ì´ë‹¤.

### Preprocessing: ë°ì´í„° ê°€ì ¸ì˜¤ê³  ë‹¤ë“¬ê¸°

#### ë°ì´í„° ê°€ì ¸ì˜¤ê¸°

ìš°ì„  ë°ì´í„° ì „ì²˜ë¦¬ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•˜ì. ì²œë¦¬ê¸¸ë„ ì„í¬íŠ¸ë¶€í„° ğŸ§—ğŸ»â€â™€ï¸

```
import numpy as np
import pandas as pd
import regex as re
import collections

from argparse import Namespace
```

ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ë“¤ë„ ì„¸íŒ…í•˜ì.

```
args = Namespace(
    raw_train_dataset_csv="/content/drive/MyDrive/NLP-Pytorch/data/yelp/raw_train.csv",
    raw_test_dataset_csv="/content/drive/MyDrive/NLP-Pytorch/data/yelp/raw_test.csv",
    proportion_subset_of_train=0.1,
    train_proportion=0.7,
    val_proportion=0.15,
    test_proportion=0.15,
    output_munged_csv="/content/drive/MyDrive/NLP-Pytorch/data/yelp/reviews_with_splits_lite.csv",
    seed=1337
)
```

ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë‹¤ë¤„ë³´ì. ë¨¼ì €, ì›ë³¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ ë‹¤ìŒ `head()`ë¡œ ë°ì´í„°ì˜ ìƒê¹€ìƒˆë¥¼ ê°„ë‹¨í•˜ê²Œ íŒŒì•…í•˜ì.

```
train_reviews = pd.read_csv(args.raw_train_dataset_csv, header=None, names=['rating', 'review'])
train_reviews.head()
```

| Â  | rating | review |
| --- | --- | --- |
| 0 | 1 | Unfortunately, the frustration of being Dr.Go... |
| 1 | 2 | Been going to Dr. Goldberg for over 10 years. ... |
| 2 | 1 | I don't know what Dr. Goldberg was like before... |
| 3 | 1 | I'm writing this review to give you a heads up... |
| 4 | 2 | All the foods is great here. But the best thing... |

#### ë°ì´í„° ë¶„ë¦¬í•˜ê¸°

ìš°ë¦¬ëŠ” ì „ì²´ ë°ì´í„°ì…‹ ì¤‘ 10%ì— í•´ë‹¹í•˜ëŠ” ì„œë¸Œì…‹ë§Œ ì‚¬ìš©í•  ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ì´ ì„œë¸Œì…‹ì— íŠ¹ì • rating ê°’ì„ ê°€ì§„ ë°ì´í„°ë§Œ í¸ì¤‘ë˜ê²Œ í¬í•¨ëœë‹¤ë©´ í•™ìŠµì´ ì œëŒ€ë¡œ ì§„í–‰ë˜ì§€ ì•Šì„ ê²ƒì´ë‹¤. ê·¸ë˜ì„œ **ì„œë¸Œì…‹ ë‚´ì˜ ê° rating í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ë™ì¼**í•˜ë„ë¡, í‘œë³¸ì§‘ë‹¨ì´ ëª¨ì§‘ë‹¨ì˜ ì„±ì§ˆì„ ë°˜ì˜í•˜ë„ë¡ ì„œë¸Œì…‹ì„ êµ¬ì„±í•´ì•¼ í•œë‹¤.

```
by_rating = collections.defaultdict(list)
for _, row in train_reviews.iterrows():
  by_rating[row.rating].append(row.to_dict())

review_subset = []

for _, item_list in sorted(by_rating.items()):
  n_total = len(item_list)  # ì „ì²´ ë°ì´í„°ì…‹ ì¤‘ í•´ë‹¹ rating valueë¥¼ ê°–ëŠ” ë°ì´í„°ì˜ ê°œìˆ˜
  n_subset = int(args.proportion_subset_of_train * n_total)
  review_subset.extend(item_list[:n_subset])  # ì „ì²´ ë°ì´í„°ì…‹ ì¤‘ n_total * 0.1ë§Œí¼ë§Œ ìŠ¬ë¼ì´ì‹±í•˜ì—¬ ì‚¬ìš©

review_subset = pd.DataFrame(review_subset)
review_subset.head()
```

| Â  | rating | review |
| --- | --- | --- |
| 0 | 1 | Unfortunately, the frustration of being Dr.Go... |
| 1 | 1 | I don't know what Dr. Goldberg was like before... |
| 2 | 1 | I'm writing this review to give you a heads up... |
| 3 | 1 | Wing sauce is like water. Pretty much a lot of... |
| 4 | 1 | Owning a driving range inside the city limits ... |

ì—¬ê¸°ì„œ ë°ì´í„°ì…‹ì˜ ê° rating í´ë˜ìŠ¤ì˜ ê°œìˆ˜ë¥¼ ì„¸ì–´ë³´ë©´ ì„œë¡œ ë™ì¼í•œ ê°œìˆ˜ì˜ ë°ì´í„°ë¥¼ ê°–ëŠ”ë‹¤.

```
train_reviews.rating.value_counts()    # 2 280000 / 1 280000
```

```
set(review_subset.rating)    # {1, 2}
```

ì´ë ‡ê²Œ ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì„ í›ˆë ¨, ê²€ì¦, í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„ë¦¬í•´ì•¼ í•œë‹¤. ë¯¸ë¦¬ ì •í•´ë‘” ê° ì„¸íŠ¸ì˜ ë¹„ìœ¨ì— ë”°ë¼ ë°ì´í„°ë¥¼ ë‚˜ëˆˆë‹¤. ê° ì„¸íŠ¸ì˜ ë¹„ìœ¨ì€ ì´ ê¸€ì˜ 2ë²ˆì§¸ ì½”ë“œë¸”ëŸ­ì—ì„œ ì„ ì–¸í•œ `args` Namespaceì— ì •ì˜ë˜ì–´ ìˆìœ¼ë©°, `args.train_proportion` = 0.75, `args.val_proportion` = 0.15, `args.test_proportion` = 0.15ë‹¤. 3ê°œì˜ ì„¸íŠ¸ë¡œ ë¶„ë¦¬í•œ ë’¤ì—ëŠ” `split` ì†ì„±ì— ì´ ë°ì´í„°ê°€ ì–´ëŠ ì„¸íŠ¸ì— ì†í•œ ë°ì´í„°ì¸ì§€ í‘œì‹œí•œë‹¤.

```
# ë³„ì  ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í›ˆë ¨, ê²€ì¦, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ë§Œë“ ë‹¤.
by_rating = collections.defaultdict(list)
for _, row in review_subset.iterrows():
  by_rating[row.rating].append(row.to_dict())

# ë¶„í•  ë°ì´í„°ë¥¼ ë§Œë“ ë‹¤.
final_list = []
np.random.seed(args.seed)

for _, item_list in sorted(by_rating.items()):
  np.random.shuffle(item_list)
  n_total = len(item_list)
  n_train = int(args.train_proportion * n_total)
  n_val = int(args.val_proportion * n_total)
  n_test = int(args.test_proportion * n_total)
    # ê° ë°ì´í„°ì— ë ˆì´ë¸”ì„ ë¶™ì—¬ì¤€ë‹¤.
  for item in item_list[:n_train]:
    item['split'] = 'train'

  for item in item_list[n_train:n_train+n_val]:
    item['split'] = 'val'

  for item in item_list[n_train+n_val:n_train+n_val+n_test]:
    item['split'] = 'test'

  final_list.extend(item_list)

final_reviews = pd.DataFrame(final_list)
```

#### ë°ì´í„° ì •ì œí•˜ê¸°

ì´í›„, ë°ì´í„°ë¥¼ ì •ì œí•˜ëŠ” ì‘ì—…ì´ í•„ìš”í•˜ë‹¤. ìš°ë¦¬ê°€ êµ¬í˜„í•  í´ë˜ìŠ¤ëŠ” ë¦¬ë·° ë°ì´í„°ë¥¼ ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í† í°ì„ íšë“í•˜ë¯€ë¡œ, êµ¬ë‘ì  ê¸°í˜¸ ì•ë’¤ì— ê³µë°±ì„ ë„£ê³ , êµ¬ë‘ì ì´ ì•„ë‹Œ ë‹¤ë¥¸ ê¸°í˜¸ë“¤ì€ ì œê±°í•œë‹¤.

```
def preprocess_text(text):
  text = text.lower()
  text = re.sub(r"([.,!?])", r" \1 ", text)
  text = re.sub(r"[^a-zA-Z.,!?]+", r" ", text)

  return text

final_reviews.review = final_reviews.review.apply(preprocess_text)
```

ë‹¤ìŒìœ¼ë¡œ, ìˆ«ì(1, 2)ë¡œ í‘œì‹œëœ `rating` ì—´ì˜ ê°’ë“¤ì„ ê°ê° 'negative'ì™€ 'positive'ë¡œ ë°”ê¿”ì¤€ë‹¤.

```
final_reviews['rating'] = final_reviews.rating.apply({1: 'negative', 2: 'positive'}.get)
```

ì˜ ë°”ë€Œì—ˆëŠ”ì§€ `final_reviews.head()`ë¡œ í™•ì¸í•´ ë³´ì.

| Â  | rating | review | split |
| --- | --- | --- | --- |
| 0 | negative | terrible place to work for i just heard a stor... | train |
| 1 | negative | hours , minutes total time for an extremely s... | train |
| 2 | negative | my less then stellar review is for service . w... | train |
| 3 | negative | i m granting one star because there s no way t... | train |
| 4 | negative | the food here is mediocre at best . i went aft... | train |

ì˜ ì²˜ë¦¬ë˜ì—ˆë‹¤! ì´ëŒ€ë¡œ csvë¡œ ì €ì¥í•˜ì ğŸ˜š

```
final_reviews.to_csv(args.output_munged_csv, index=False)
```

ë‹¤ìŒìœ¼ë¡œ, ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì„ ê°€ì§€ê³  ë³¸ê²©ì ìœ¼ë¡œ ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³¼ ê²ƒì´ë‹¤.
ì „ì²˜ë¦¬ê°€ ëë‚œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í°í™”, ë²¡í„°í™”í•œ í›„ Datasetìœ¼ë¡œ ë§Œë“œëŠ” ê³¼ì •ì„ ì½”ë“œë¡œ ì‘ì„±í•´ë³´ì. ìš°ë¦¬ëŠ” ì—¬ê¸°ì„œ `ReviewDataset`, `Vocabulary`, `ReviewVectorizer` í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ ê²ƒì´ë‹¤.
- `ReviewDataset`: csv íŒŒì¼ì„ ë°›ì•„ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³ , ì´ ë°ì´í„°ì…‹ì„ ë°”íƒ•ìœ¼ë¡œ `ReviewVectorizer` ê°ì²´ë¥¼ ë§Œë“ ë‹¤.
- `ReviewVectorizer`: ê°ê° ë¦¬ë·°ì™€ ë³„ì  ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” `Vocabulary` ê°ì²´ 2ê°œë¥¼ ë§Œë“¤ì–´ ê´€ë¦¬í•œë‹¤.
- `Vocabulary`: ê°ì²´ëŠ” ë§¤í•‘ì„ ìœ„í•´ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ì–´íœ˜ ì‚¬ì „ì„ ë§Œë“œëŠ” í´ë˜ìŠ¤ë¡œ, ê° í† í°ê³¼ ê³ ìœ ê°’(ì •ìˆ˜)ë¥¼ ë§¤í•‘í•œë‹¤.



### íŒŒì´í† ì¹˜ ë°ì´í„°ì…‹ ì´í•´í•˜ê¸°

íŒŒì´í† ì¹˜ëŠ” `Dataset` í´ë˜ìŠ¤ë¡œ ë°ì´í„°ì…‹ì„ ì¶”ìƒí™”í•œë‹¤. `Dataset` ëŠ” ì¶”ìƒí™”ëœ ë°˜ë³µì(iterator) í´ë˜ìŠ¤ë¡œ, íŒŒì´í† ì¹˜ì—ì„œ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ë•Œ ë¨¼ì € `Dataset` í´ë˜ìŠ¤ë¥¼ ìƒì†í•´ì„œ `__getitem__()`ê³¼ `__len__()` ë©”ì„œë“œë¥¼ í•„ìˆ˜ì ìœ¼ë¡œ êµ¬í˜„í•´ì•¼ í•œë‹¤.
ì•„ë˜ì˜ ì½”ë“œì—ì„œëŠ” `Dataset`ì„ ìƒì†í•œ `ReviewDataset` í´ë˜ìŠ¤ì™€ í•¨ê»˜ `ReviewVectorizer`ì™€ `DataLoader`ë¥¼ ì‚¬ìš©í•œë‹¤.
ì—¬ê¸°ì„œ êµ¬í˜„í•  `ReviewDataset` í´ë˜ìŠ¤ëŠ” ì•„ë˜ 3ê°€ì§€ ì¡°ê±´ì„ ë§Œì¡±í•œë‹¤ê³  ê°€ì •í•œë‹¤.

- ë°ì´í„°ì…‹ì´ ìµœì†Œí•œìœ¼ë¡œ ì •ì œë˜ì–´ ìˆê³ , í›ˆë ¨, ê²€ì¦, í…ŒìŠ¤íŠ¸ setìœ¼ë¡œ ë‚˜ëˆ„ì–´ì ¸ ìˆë‹¤.
- ì´ ë°ì´í„°ì…‹ì˜ ë¦¬ë·°ë¥¼ ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ë©´ í† í° ë¦¬ìŠ¤íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.
- ë°ì´í„° ìƒ˜í”Œì— ì´ ìƒ˜í”Œì´ í›ˆë ¨, ê²€ì¦, ì„¸íŠ¸ ì¤‘ ì–´ëŠ ì„¸íŠ¸ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í‘œì‹œë˜ì–´ ìˆë‹¤.

ì•„ë˜ëŠ” `ReviewDataset`ì„ êµ¬í˜„í•œ ì½”ë“œë‹¤. @classmethodë¡œ í´ë˜ìŠ¤ì˜ ì§„ì…ì ì„ ì§€ì •í–ˆë‹¤. @classmethodì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ [ì—¬ê¸°](https://wikidocs.net/16074)ë¥¼ ì°¸ê³ í•˜ì.
```python
class ReviewDataset(Dataset):
  def __init__(self, review_df, vectorizer):
    """
    ë§¤ê°œë³€ìˆ˜:
      review_df(pandas.DataFrame): ë°ì´í„°ì…‹
      vectorizer(ReviewVectorizer): ReviewVectorizer ê°ì²´
    """
    self.review_df = review_df
    self._vectorizer = vectorizer
    
    self.train_df = self.review_df[self.review_df.split=='train']
    self.train_size = len(self.train_df)

    self.val_df = self.review_df[self.review_df.split=='val']
    self.validation_size = len(self.val_df)

    self.test_df = self.review_df[self.review_df.split=='test']
    self.test_size = len(self.test_df)

    self._lookup_dict = {'train': (self.train_df, self.train_size),
                         'val': (self.val_df, self.validation_size),
                         'test': (self.test_df, self.test_size)}
    
    self.set_split('train')
  
  @classmethod # ì •ì  ë©”ì„œë“œ, í´ë˜ìŠ¤ì—ì„œ ì§ì ‘ ì ‘ê·¼í•  ìˆ˜ ìˆìŒ. ìì‹ í´ë˜ìŠ¤ì¸ ê²½ìš° ë¶€ëª¨ í´ë˜ìŠ¤ê°€ ì•„ë‹Œ ìì‹ í´ë˜ìŠ¤(ìì‹ )ì˜ ì†ì„±ì„ ì‚¬ìš©í•¨
  def load_dataset_and_make_vectorizer(cls, review_csv):
    """
    ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ìƒˆë¡œìš´ ReviewVectorizer ê°ì²´ë¥¼ ë§Œë“ ë‹¤.
    ë§¤ê°œë³€ìˆ˜:
      review_csv(str): ë°ì´í„°ì…‹ì˜ ìœ„ì¹˜
    ë°˜í™˜ê°’:
      ReviewDatasetì˜ ì¸ìŠ¤í„´ìŠ¤
    """
    review_df = pd.read_csv(review_csv)
    train_review_df = review_df[review_df.split=='train']
    return cls(review_df, ReviewVectorizer.from_dataframe(train_review_df))
  
  @classmethod
  def load_dataset_and_load_vectorizer(cls, review_csv, vectorizer_filepath):
    """
    ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ìƒˆë¡œìš´ ReviewVectorizer ê°ì²´ë¥¼ ë§Œë“ ë‹¤.
    ìºì‹œëœ ReviewVectorizer ê°ì²´ë¥¼ ì¬ì‚¬ìš©í•  ë•Œ ì‚¬ìš©í•œë‹¤.
    ë§¤ê°œë³€ìˆ˜:
      review_csv(str): ë°ì´í„°ì…‹ì˜ ìœ„ì¹˜
      vectorizer_filepath(str): ReviewVectorizer ê°ì²´ì˜ ì €ì¥ ìœ„ì¹˜
    ë°˜í™˜ê°’:
      ReviewDatasetì˜ ì¸ìŠ¤í„´ìŠ¤
    """
    review_df = pd.read_csv(review_csv)
    vectorizer = cls.load_vectorizer_only(vectorizer_filepath)
    return cls(review_df, vectorizer)

  @staticmethod
  def load_vectorizer_only(vectorizer_filepath):
    """
    íŒŒì¼ì—ì„œ ReviewVectorizer ê°ì²´ë¥¼ ë¡œë“œí•˜ëŠ” ì •ì  ë©”ì„œë“œ
    ë§¤ê°œë³€ìˆ˜:
      vectorizer_filepath(str): ì§ë ¬í™”ëœ ReviewVectorizer ê°ì²´ì˜ ìœ„ì¹˜
    ë°˜í™˜ê°’:
      ReviewVectorizerì˜ ì¸ìŠ¤í„´ìŠ¤
    """
    with open(vectorizer_filepath) as fp:
      return ReviewVectorizer.from_serializable(json.load(fp))
    
  def save_vectorizer(self, vectorizer_filepath):
    """
    ReviewVectorizer ê°ì²´ë¥¼ json í˜•íƒœë¡œ ë””ìŠ¤í¬ì— ì €ì¥
    ë§¤ê°œë³€ìˆ˜:
      vectorizer_filepath(str): ì§ë ¬í™”ëœ ReviewVectorizer ê°ì²´ë¥¼ ì €ì¥í•  ìœ„ì¹˜
    """
    with open(vectorizer_filepath, "w") as fp:
      json.dump(self._vectorizer.to_serializable(), fp)
  
  def get_vectorizer(self):
    """ ë²¡í„° ë³€í™˜ ê°ì²´ë¥¼ ë°˜í™˜ """
    return self._vectorizer
  
  def set_split(self, split="train"):
    """
    ë°ì´í„°í”„ë ˆì„ì— ìˆëŠ” ì—´ì„ ì‚¬ìš©í•´ ë°ì´í„°ì…‹ì„ ì„ íƒ
    ë§¤ê°œë³€ìˆ˜:
      split(str): "train" or "val" or "test"
    """
    self._target_split = split
    self._target_df, self._target_size = self._lookup_dict[split]
  
  def __len__(self):
    return self._target_size
  
  def __getitem__(self, index):
    """
    íŒŒì´í† ì¹˜ ë°ì´í„°ì…‹ì˜ ì£¼ìš” ì§„ì… ë©”ì„œë“œ
    ë§¤ê°œë³€ìˆ˜:
      index(int): ë°ì´í„° í¬ì¸íŠ¸ì˜ ì¸ë±ìŠ¤
    ë°˜í™˜ê°’:
      ë°ì´í„° í¬ì¸íŠ¸ì˜ íŠ¹ì„±(x_data)ê³¼ ë ˆì´ë¸”(y_target)ë¡œ ì´ë£¨ì–´ì§„ ë”•ì…”ë„ˆë¦¬
    """
    row = self._target_df.iloc[index]
    review_vector = self._vectorizer.vectorize(row.review)
    rating_index = self._vectorizer.rating_vocab.lookup_token(row.rating)
    return {'x_data': review_vector,
            'y_target': rating_index}
  
  def get_num_batches(self, batch_size):
    """
    ë°°ì¹˜ í¬ê¸°ê°€ ì£¼ì–´ì§€ë©´ ë°ì´í„°ì…‹ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ë°°ì¹˜ ê°œìˆ˜ë¥¼ ë°˜í™˜
    ë§¤ê°œë³€ìˆ˜:
      batch_size(int)
    ë°˜í™˜ê°’:
      ë°°ì¹˜ ê°œìˆ˜
    """
    return len(self) // batch_size
```

### Vocabularyì™€ ReviewVectorizer, DataLoader
ì´ ì˜ˆì œì—ì„œëŠ” `Vocabulary`ì™€ `ReviewVectorizer`, `DataLoader`ë¥¼ í†µí•´ ê° í† í°(ë‹¨ì–´)ë¥¼ ì •ìˆ˜ì— ë§¤í•‘í•˜ê³ , ì´ ë§¤í•‘ì„ ê° ë°ì´í„° í¬ì¸íŠ¸ì— ì ìš©í•´ ë²¡í„° í˜•íƒœë¡œ ë³€í™˜í•œ ë’¤ì— ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¯¸ë‹ˆë°°ì¹˜ë¡œ ëª¨ì€ë‹¤.

#### Vocabulary
í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ì˜ ë¯¸ë‹ˆë°°ì¹˜ë¡œ ë°”ê¾¸ëŠ” ì²«ë²ˆì§¸ ë‹¨ê³„ëŠ” í† í°ì„ ì •ìˆ˜ë¡œ ë§¤í•‘í•˜ëŠ” ê²ƒì´ë‹¤. `Vocabulary` í´ë˜ìŠ¤ëŠ” {ì¸ë±ìŠ¤:í† í°} ë”•ì…”ë„ˆë¦¬ì™€ {í† í°:ì¸ë±ìŠ¤} ë”•ì…”ë„ˆë¦¬ë¥¼ ìº¡ìŠí™”í•œë‹¤. ì‚¬ìš©ìê°€ ë”•ì…”ë„ˆë¦¬ì— ìƒˆë¡œìš´ í† í°ì„ ì¶”ê°€í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ë±ìŠ¤ë¥¼ ì¦ê°€ì‹œí‚¤ê³ , íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ í›ˆë ¨ ê³¼ì •ì—ì„œ ë³¸ ì ì´ ì—†ê±°ë‚˜ ì¶œí˜„ ë¹ˆë„ê°€ ë‚®ì•˜ë˜ í† í°ì„ ë°›ì•˜ì„ ë•Œì— `UNK`(unknown)ë¼ëŠ” íŠ¹ë³„ í† í°ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤. 
```python
class Vocabulary(object):
  """ ë§¤í•‘ì„ ìœ„í•´ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ì–´íœ˜ ì‚¬ì „ì„ ë§Œë“œëŠ” í´ë˜ìŠ¤ """
  def __init__(self, token_to_idx=None, add_unk=True, unk_token="<UNK>"):
    """
    ë§¤ê°œë³€ìˆ˜:
      token_to_idx(dict): ê¸°ì¡´ í† í°-ì¸ë±ìŠ¤ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
      add_unk(bool): UNK í† í°ì„ ì¶”ê°€í• ì§€ ì§€ì •í•˜ëŠ” í”Œë˜ê·¸
      unk_token(str): Vocabularyì— ì¶”ê°€í•  UNK í† í°
    """
    if token_to_idx is None:
      token_to_idx = {}
    self._token_to_idx = token_to_idx
    self._idx_to_token = {idx: token for token, idx in self._token_to_idx.items()}
    self._add_unk = add_unk
    self._unk_token = unk_token
    self.unk_index = -1
    if add_unk:
      self.unk_index = self.add_token(unk_token)
    
  
  def to_serializable(self):
    """ ì§ë ¬í™”í•  ìˆ˜ ìˆëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ """
    return {'token_to_idx': self._token_to_idx,
            'add_unk': self._add_ink,
            'unk_token': self._unk_token}
  
  
  @classmethod
  def from_serializable(cls, contents):
    """ ì§ë ¬í™”ëœ ë”•ì…”ë„ˆë¦¬ì—ì„œ Vocabulary ê°ì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤ """
    return cls(**contents)  # --> ?
  
  
  def add_token(self, token):
    """ í† í°ì„ ê¸°ë°˜ìœ¼ë¡œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤(ì¶”ê°€)
    ë§¤ê°œë³€ìˆ˜:
      token(str): Vocabularyì— ì¶”ê°€í•  í† í°
    ë°˜í™˜ê°’:
      index(int): í† í°ì— ìƒì‘í•˜ëŠ” ì •ìˆ˜
    """
    if token in self._token_to_idx:
      index = self._token_to_idx[token]
    else:
      index = len(self._token_to_idx)
      self._token_to_idx[token] = index
      self._idx_to_token[index] = token
    return index


    def add_many(self, tokens):
      """ í† í° ë¦¬ìŠ¤íŠ¸ë¥¼ Vocabularyì— ì¶”ê°€í•©ë‹ˆë‹¤.
      ë§¤ê°œë³€ìˆ˜:
        tokens(list): Vocabularyì— ì¶”ê°€í•  ë¬¸ìì—´ í† í° ë¦¬ìŠ¤íŠ¸
      ë°˜í™˜ê°’:
        indices(list): í† í° ë¦¬ìŠ¤íŠ¸ì— ìƒì‘ë˜ëŠ” ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
      """
      return [self.add_token(token) for token in tokens]
    

    def lookup_token(self, token):
      """ í† í°ì— ëŒ€ì‘í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
      í† í°ì´ ì—†ìœ¼ë©´ UNK ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
      ë§¤ê°œë³€ìˆ˜:
        token(str): ì°¾ì„ í† í°
      ë°˜í™˜ê°’:
        index(int): í† í°ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤
      ë…¸íŠ¸:
        UNK í† í°ì„ ì‚¬ìš©í•˜ë ¤ë©´ (Vocabularyì— ì¶”ê°€í•˜ê¸° ìœ„í•´) `unk_index`ê°€ 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.
      """
      if self.unk_index >= 0:
        return self._token_to_idx.get(token, self.unk_index)
      else:
        return self._token_to_idx[token]
    

    def lookup_index(self, index):
      """ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” í† í°ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
      ë§¤ê°œë³€ìˆ˜:
        index(int): ì°¾ì„ ì¸ë±ìŠ¤
      ë°˜í™˜ê°’:
        token(str): ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” í† í°
      ì—ëŸ¬:
        KeyError: ì¸ë±ìŠ¤ê°€ Vocabularyì— ì—†ì„ ë•Œ ë°œìƒí•©ë‹ˆë‹¤.
      """
      if index not in self._idx_to_token:
        raise KeyError("Vocabularyì— ì¸ë±ìŠ¤(%d)ê°€ ì—†ìŠµë‹ˆë‹¤." % index)
      return self._idx_to_token[index]


    def __str__(self):
      return "<Vocabulary(size=%d)>" % len(self)
    

    def __len__(self):
      return len(self._token_to_idx)
```

#### ReviewVectorizer
í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë²¡í„°ì˜ ë¯¸ë‹ˆë°°ì¹˜ë¡œ ë§Œë“œëŠ” ë‘ë²ˆì§¸ ë‹¨ê³„ëŠ” ì…ë ¥ ë°ì´í„° í¬ì¸íŠ¸ì˜ í† í°ì„ ìˆœíšŒí•˜ë©´ì„œ ê° í† í°ì„ ì •ìˆ˜ë¡œ ë°”ê¾¸ëŠ” ê²ƒì´ë‹¤. `ReviewVectorizer` í´ë˜ìŠ¤ëŠ” í† í°ê³¼ ì¸ë±ìŠ¤ê°€ ë§¤í•‘ë˜ì–´ ìˆëŠ” `Vocabulary` ê°ì²´ì˜ lookup í…Œì´ë¸”ì„ ì°¸ê³ í•˜ì—¬ ì…ë ¥ë°›ì€ ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ one-hot ë²¡í„°ë¡œ ë³€í™˜í•œë‹¤. 
```python
class ReviewVectorizer(object):
  """ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì¹˜ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤ """
  def __init__(self, review_vocab, rating_vocab):
    """
    ë§¤ê°œë³€ìˆ˜:
      review_vocab(Vocabulary): ë‹¨ì–´ë¥¼ ì •ìˆ˜ì— ë§¤í•‘í•˜ëŠ” Vocabulary
      rating_vocab(Vocabulary): í´ë˜ìŠ¤ ë ˆì´ë¸”ì„ ì •ìˆ˜ì— ë§¤í•‘í•˜ëŠ” Vocabulary
    """
    self.review_vocab = review_vocab
    self.rating_vocab = rating_vocab
  
  
  def vectorize(self, review):
    """ ë¦¬ë·°ì— ëŒ€í•œ ì›-í•« ë²¡í„°ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    ë§¤ê°œë³€ìˆ˜:
      review(str): ë¦¬ë·°
    ë°˜í™˜ê°’:
      one_hot(np.ndarray): ì›-í•« ë²¡í„°
    """
    one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)

    for token in review.split(" "):
      if token not in string.punctuation:
        one_hot[self.review_vocab.lookup_token(token)] = 1
    
    return one_hot
  

  @classmethod
  def from_dataframe(cls, review_df, cutoff=25):
    """ ë°ì´í„°ì…‹ ë°ì´í„°í”„ë ˆì„ì—ì„œ Vectorizer ê°ì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    ë§¤ê°œë³€ìˆ˜:
      tokens(list): Vocabularyì— ì¶”ê°€í•  ë¬¸ìì—´ í† í° ë¦¬ìŠ¤íŠ¸
    ë°˜í™˜ê°’:
      indices(list): í† í° ë¦¬ìŠ¤íŠ¸ì— ìƒì‘ë˜ëŠ” ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
    """
    review_vocab = Vocabulary(add_unk=True)
    rating_vocab = Vocabulary(add_unk=False)

    # ì ìˆ˜ ì¶”ê°€
    for rating in sorted(set(review_df.rating)):
      rating_vocab.add_token(rating)
    
    # count > cutoffì¸ ë‹¨ì–´ ì¶”ê°€
    word_counts = Counter()
    for review in review_df.review:
      for word in review.split(" "):
        if word not in string.punctuation:
          word_counts[word] += 1
    
    for word, count in word_counts.items():
      if count > cutoff:
        review_vocab.add_token(word)
    
    return cls(review_vocab, rating_vocab)
  

  @classmethod
  def from_serializable(cls, contents):
    """ ì§ë ¬í™”ëœ ë”•ì…”ë„ˆë¦¬ì—ì„œ ReviewVectorizer ê°ì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    ë§¤ê°œë³€ìˆ˜:
      contents(dict): ì§ë ¬í™”ëœ ë”•ì…”ë„ˆë¦¬
    ë°˜í™˜ê°’:
      ReviewVectorizer í´ë˜ìŠ¤ ê°ì²´
    """
    review_vocab = Vocabulary.from_serializable(contents['review_vocab'])
    rating_vocab = Vocabulary.from_serializable(contents['rating_vocab'])

    return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)
  
  
  def to_serializable(self):
    """ ìºì‹±ì„ ìœ„í•´ ì§ë ¬í™”ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    ë°˜í™˜ê°’:
      contents(dict): ì§ë ¬í™”ëœ ë”•ì…”ë„ˆë¦¬
    """
    return {'review_vocab': self.review_vocab.to_serializable(),
            'rating_vocab': self.rating_vocab.to_serializable()}
```

#### DataLoader
íŒŒì´í”„ë¼ì¸ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” ë²¡í„°ë¡œ ë³€í™˜í•œ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ëª¨ìœ¼ëŠ” ê²ƒì´ë‹¤. íŒŒì´í† ì¹˜ì˜ ë‚´ì¥ í´ë˜ìŠ¤ì¸ `DataLoader`ëŠ” ì‹ ê²½ë§ í›ˆë ¨ì— ê¼­ í•„ìš”í•œ ë¯¸ë‹ˆë°°ì¹˜ë¡œ ëª¨ìœ¼ëŠ” ì‘ì—…ì„ í¸í•˜ê²Œ í•´ì¤€ë‹¤.
```python
def generate_batches(dataset, batch_size, shuffle=True, drop_last=True, device="cpu"):
  """
  íŒŒì´í† ì¹˜ DataLoaderë¥¼ ê°ì‹¸ê³  ìˆëŠ” ì œë„ˆë ˆì´í„° í•¨ìˆ˜ì…ë‹ˆë‹¤.
  ê° í…ì„œë¥¼ ì§€ì •ëœ ì¥ì¹˜ë¡œ ì´ë™í•©ë‹ˆë‹¤.
  """
  dataloader = DataLoader(dataset=dataset, batch_size=batch_size,
                          shuffle=shuffle, drop_last=drop_last)
  
  for data_dict in dataloader:
    out_data_dict = {}
    for name, tensor in data_dict.items():
      out_data_dict[name] = data_dict[name].to(device)
    yield out_data_dict
```
